# backend/app/config.yaml

llm:
  primary_model: meta-llama/llama-4-maverick-17b-128e-instruct
  fallback_model: meta-llama/llama-4-scout-17b-16e-instruct
  temperature: 0.1
  retry:
    attempts: 3
    backoff_multiplier: 1
    backoff_min: 2
    backoff_max: 60

faiss:
  pickle_path: "faiss_stores/faiss_all_campaigns_text"

groq:
  api_key_env: GROQ_API_KEY

embeddings:
  model_name: all-MiniLM-L6-v2
# you can add more sections here (mlflow, embeddings, etc.)

mapping:
  manifest: "src/campaigns_manifest/kusama_campaign.json"